# Generative AI Lab  
## Domain Translation & Image Synthesis

**Project Status:** âœ… Completed  
**Frameworks:** PyTorch, Torchvision  
**Architectures:** CycleGAN (ResNet-based), Diffusion Model (U-Net based)

---

## ğŸ“– Project Overview

This project explores two fundamental paradigms of modern **Generative AI**:

- Unpaired Image-to-Image Translation  
- Denoising Diffusion Probabilistic Models (DDPM)

The goal is to demonstrate how neural networks can modify existing reality through translation and generate structure from random noise through probabilistic modeling.

The project consists of two independent generative engines:
- **The Translator (CycleGAN)**
- **The Denoiser (Diffusion Model)**

---

## ğŸ“‚ Project Structure

```bash

Generative_AI_Lab/
â”‚
â”œâ”€â”€ checkpoints/             # Saved model weights  
â”‚   â”œâ”€â”€ cyclegan/            # Horse â†’ Zebra model  
â”‚   â””â”€â”€ diffusion/           # Diffusion model  
â”‚
â”œâ”€â”€ data/                    # Datasets  
â”‚   â”œâ”€â”€ horse2zebra/         # Unpaired training images  
â”‚   â””â”€â”€ denoise_data/        # CIFAR-10 (binary format)  
â”‚
â”œâ”€â”€ models/                  # Model architectures  
â”‚   â”œâ”€â”€ cycle_gan.py         # ResNet Generator & PatchGAN Discriminator  
â”‚   â””â”€â”€ unet.py              # U-Net for diffusion  
â”‚
â”œâ”€â”€ utils/  
â”‚   â””â”€â”€ diffusion_utils.py   # Noise scheduling & diffusion math  
â”‚
â”œâ”€â”€ train_translator.py      # CycleGAN training  
â”œâ”€â”€ test_translator.py       # Translation visualization  
â”‚
â”œâ”€â”€ train_denoiser.py        # Diffusion training  
â”œâ”€â”€ test_denoiser.py         # Noise â†’ Image restoration  
â”‚
â””â”€â”€ README.md

```

---

## âš™ï¸ Requirements

```bash
pip install torch torchvision matplotlib tqdm requests pillow
```

---

## ğŸ“¥ Data Setup

Run this script first to download and organize the required datasets (Horse2Zebra and CIFAR-10):

```bash
python download_data.py
```

---

## ğŸ–¥ï¸ Hardware Used

- **GPU:** NVIDIA RTX 3050 (4GB VRAM)  
- **CUDA:** 11.8 / 12.x  

---

## ğŸ¦“ Engine 1: The Translator (CycleGAN)

Implements **Cycle-Consistent Adversarial Networks**  
(Zhu et al., ICCV 2017).

### Concept

Learns bidirectional mappings:
- **G: X â†’ Y** (Horse â†’ Zebra)  
- **F: Y â†’ X**  

With cycle consistency:
F(G(X)) â‰ˆ X

### Architecture

- Generator: ResNet-based (9 residual blocks)  
- Discriminator: PatchGAN (70Ã—70)  
- Loss:
  - Adversarial Loss  
  - Cycle Consistency Loss  

### How to Run

Train:
```bash
python train_translator.py
```

Test:
```bash
python test_translator.py
```

---

## ğŸŒ«ï¸ Engine 2: The Denoiser (Diffusion Model)

Implements a simplified **DDPM**  
(Ho et al., NeurIPS 2020).

### Concept

- Forward process: Adds Gaussian noise  
- Reverse process: U-Net predicts and removes noise  

### Architecture

- Backbone: U-Net  
- Objective: Minimize MSE between actual and predicted noise  

### How to Run

Train:
```bash
python train_denoiser.py
```

Test:
```bash
python test_denoiser.py
```

---

## ğŸ“Š Results & Observations

### CycleGAN
- Early epochs: Blurry structure  
- Later epochs: Clear zebra patterns  

### Diffusion
- Recovers semantic structure from heavy noise  
- Demonstrates learned image distribution  

---

## ğŸ“š References

- Zhu et al., ICCV 2017  
- Ho et al., NeurIPS 2020  
- Krizhevsky et al., CIFAR-10  

---

## ğŸ§ª Summary

This project demonstrates adversarial learning and probabilistic generative modeling for image translation and synthesis.
